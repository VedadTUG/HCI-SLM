# HCI-SLM - Comparing energy consumption of selected small language model

This project provides supplementary information for a publication in preparation.

## This work serves in two ways:
First, we encourage to question the use of generative language models in the context of sustainability. We scrutinize algorithmic energy consumption to considerate sustainable usage, and shall raise awareness for emission-based model and hardware optimization.
Secondly, we present a comparison of small language models that serves as a guide for selecting a small language model that efficiently performs on local hardware at home.

## Selected Models for comparison: 
TinyLlama (Apache License 2.0), NanoGPT (MIT)

## Implementation
We use Python and the library CodeCarbon for all tests, measurements and plots. Code is organized in subfolders respectively. 
See [instructions.txt](instructions.txt).
